# Poker32
Mastering Poker32 with Reinforcement Learning


## TODOS

Game engine
Random agent
RL agent
training RL agent
Human agent
Human agent UI
todo Self-Play with Counterfactual Baseline
todo train in a tournament
todo entropy bonus  -β Σ π(a) log π(a)        (β ≈ 0.01)

---

## Notes

- training a policy to counter a given strategy lets you find out whether that strategy is GTO or not.
- split-pot conflicts with Self-Play with Counterfactual Baseline 
- keep track of how many times each action was picked
- how to handle button? shuffle players?
